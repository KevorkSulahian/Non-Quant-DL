{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets evaluate transformers rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c815daab3743407a835c2dee6eeaaa64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36.2\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26a309407314075af15888d2050f59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678f7946e44548639d13bc6fdbf1c0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad556b425a9147f49d8fb7ec140c1858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9962508feea04b5094587136afee6e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67efcb87e6f44cf9575e08374b4e75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6201d43660c4c01a3b0d70331f409d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c04695fbe5d44e5898897b60a565c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46886a3ed1514b8faae6352bffe45c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5294de99f9754e1d8cfc2961034e15df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "raw_datasets = load_dataset(\"xsum\")\n",
    "metric = load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document', 'summary', 'id'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"test\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=2):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test your news knowledge with our 12 days of Christmas news quizzes.\\nThis quiz is day five and asks questions about the month of May 2016.</td>\n",
       "      <td>How much do you remember about the news in Wales over the past 12 months?</td>\n",
       "      <td>38366837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterman said he was selling the collection, which included 56 Gauge 1 steam models, to fund apprenticeships at the heritage trust he runs.\\nTwo of the models sold for £124,000 each, while another went for £86,800.\\nHe said the engines had realised what he wanted and he had raised \"not far off\" the amount he hoped.\\nA Beyer Goods, which Waterman said was \"the greatest steam railway engine built in miniature\", was one of the models to fetch £120,000.\\nThe sale of 32 of the models fetched a total of £627,229, including buyers' premium.\\nThe remaining 24 models failed to reach their reserve price and were not sold, but post-sale offers are continuing to come in, the auctioneers said.\\nWaterman described the engines, built from scratch for him, as \"the Fabergé eggs of the railway world\".\\nHe said he had decided to sell what amounts to around a tenth of his collection in order to raise enough money to secure the future of the Waterman Railway Heritage Trust, which holds his collection of full-size steam engines.\\nHe said the pieces he was selling no longer fitted \"into his wider collection\".\\n\"I never run that stuff any more,\" he said. \"Everything I'm selling is unique. It was all built for me.\\n\"They are one-offs. They are not toys - they are works of art. That's why they are so pricey.\"\\nThe sale was carried out by at Dreweatts and Bloomsbury Auctions.\\nThe house's steam and model engineering consultant Michael Matthews said: \"The collection is unique.\\n\"These models were all built from scratch. They were commissioned over a period of 20 years and Mr Waterman got some of the best builders at the time to work for him - few other people would have had the wealth and enthusiasm to do that.\"</td>\n",
       "      <td>An auction of part of the model railway collection owned by record producer Pete Waterman has raised more than £600,000.</td>\n",
       "      <td>32331602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [\"hello there\", \"general kenobi\"]\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"document\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4324fe35d47244e6860fd2b93ae8ea4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caabc4c73c4340788813a60639148fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb5dedf7380435a9c59a52751af6a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset smaller by half\n",
    "tokenized_datasets['train'] = tokenized_datasets['train'].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['validation'] = tokenized_datasets['validation'].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11332"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last thing to define for our Seq2SeqTrainer is how to compute the metrics from the predictions. \n",
    "# We need to define a function for this, which will just use the metric we loaded earlier, \n",
    "# and we have to do a bit of pre-processing to decode the predictions into texts:\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fae061e048424698f1750ba9bc80f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c972148a0f44f759fa25c47b710c400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7, training_loss=3.8635292053222656, metrics={'train_runtime': 264.2064, 'train_samples_per_second': 0.378, 'train_steps_per_second': 0.026, 'train_loss': 3.8635292053222656, 'epoch': 1.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28cec8163ae4d7c87333c9f3ffca327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b415ef80dc84c8aa7b5e681a7520274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930d75aaa34045be9e5034e6aa721cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/herooooooooo/t5-small-finetuned-xsum/commit/0e511a04eb6a30cc650b5c830dd726110593be88', commit_message='End of training', commit_description='', oid='0e511a04eb6a30cc650b5c830dd726110593be88', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b403501349145978bcf5ef224b10fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevol\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kevol\\.cache\\huggingface\\hub\\models--herooooooooo--t5-small-finetuned-xsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060a9ec429964964955fff68e951ec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d980e82d9c2d4faaa06defb71ce8ffd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "# example\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"herooooooooo/t5-small-finetuned-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction on a given text\n",
    "\n",
    "text = \"Waterman said he was selling the collection, which included 56 Gauge 1 steam models, to fund apprenticeships at the heritage trust he runs.\\nTwo of the models sold for £124,000 each, while another went for £86,800.\\nHe said the engines had realised what he wanted and he had raised not far off the amount he hoped.\\nA Beyer Goods, which Waterman said was the greatest steam railway engine built in miniature, was one of the models to fetch £120,000.\\nThe sale of 32 of the models fetched a total of £627,229, including buyers' premium.\\nThe remaining 24 models failed to reach their reserve price and were not sold, but post-sale offers are continuing to come in, the auctioneers said.\\nWaterman described the engines, built from scratch for him, as the Fabergé eggs of the railway world.\\nHe said he had decided to sell what amounts to around a tenth of his collection in order to raise enough money to secure the future of the Waterman Railway Heritage Trust, which holds his collection of full-size steam engines.\\nHe said the pieces he was selling no longer fitted into his wider collection.\\nI never run that stuff any more, he said. Everything I'm selling is unique. It was all built for me.\\nThey are one-offs. They are not toys - they are works of art. That's why they are so pricey.\\nThe sale was carried out by at Dreweatts and Bloomsbury Auctions.\\nThe house's steam and model engineering consultant Michael Matthews said: The collection is unique.\\nThese models were all built from scratch. They were commissioned over a period of 20 years and Mr Waterman got some of the best builders at the time to work for him - few other people would have had the wealth and enthusiasm to do that.\"\n",
    "inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "# outputs = model.generate(inputs, max_length=150, min_length=5, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "# print(tokenizer.decode(outputs[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json\n",
    "import json\n",
    "\n",
    "\n",
    "with open('input.json', 'w') as f:\n",
    "    json.dump({\n",
    "        \"input_data\": inputs.tolist(),\n",
    "        \"params\": {\n",
    "            \"max_length\": 150,\n",
    "            \"min_length\": 5,\n",
    "            \"length_penalty\": 2.0,\n",
    "            \"num_beams\": 4,\n",
    "            \"early_stopping\": True\n",
    "        }\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example NumPy array of inputs; replace this with your actual inputs\n",
    "import numpy as np\n",
    "inputs = np.array([[21603, 10, 2336, 348, 243, 3, 88, 47, 3014, 8, 1232, 6, 84, 1285, 11526, 12520, 397, 209, 7222, 2250, 6, 12, 3069, 28489, 7, 44, 8, 8681, 2019, 3, 88, 3154, 5, 2759, 13, 8, 2250, 1916, 21, 11140, 357, 13161, 284, 6, 298, 430, 877, 21, 3996, 3840, 6, 6192, 5, 216, 243, 8, 7277, 141, 3, 19007, 125, 3, 88, 1114, 11, 3, 88, 141, 3279, 59, 623, 326, 8, 866, 3, 88, 3, 20964, 5, 71, 493, 7975, 1804, 7, 6, 84, 2336, 348, 243, 47, 8, 4016, 7222, 14421, 1948, 1192, 16, 20955, 6, 47, 80, 13, 8, 2250, 12, 27109, 11140, 13922, 5, 37, 1048, 13, 3538, 13, 8, 2250, 3, 89, 25872, 3, 9, 792, 13, 3996, 948, 2555, 6, 357, 3166, 6, 379, 6094, 31, 3331, 5, 37, 4080, 997, 2250, 4567, 12, 1535, 70, 7866, 594, 11, 130, 59, 1916, 6, 68, 442, 18, 7, 9, 109, 704, 33, 6168, 12, 369, 16, 6, 8, 8493, 15, 277, 243, 5, 2336, 348, 3028, 8, 7277, 6, 1192, 45, 8629, 21, 376, 6, 38, 8, 1699, 2235, 154, 5875, 13, 8, 14421, 296, 5, 216, 243, 3, 88, 141, 1500, 12, 1789, 125, 6201, 12, 300, 3, 9, 3, 324, 189, 13, 112, 1232, 16, 455, 12, 3033, 631, 540, 12, 2451, 8, 647, 13, 8, 2336, 348, 18025, 11523, 5313, 6, 84, 4532, 112, 1232, 13, 423, 18, 7991, 7222, 7277, 5, 216, 243, 8, 2161, 3, 88, 47, 3014, 150, 1200, 9695, 139, 112, 6281, 1232, 5, 27, 470, 661, 24, 2005, 136, 72, 6, 3, 88, 243, 5, 7462, 27, 31, 51, 3014, 19, 775, 5, 94, 47, 66, 1192, 21, 140, 5, 328, 33, 80, 18, 1647, 7, 5, 328, 33, 59, 8723, 3, 18, 79, 33, 930, 13, 768, 5, 466, 31, 7, 572, 79, 33, 78, 594, 63, 5, 37, 1048, 47, 4006, 91, 57, 44, 24348, 1544, 17, 7, 11, 17762, 7, 7165, 23040, 7, 5, 37, 629, 31, 7, 7222, 11, 825, 3867, 7792, 2457, 9771, 7, 243, 10, 37, 1232, 19, 775, 5, 506, 2250, 130, 66, 1192, 45, 8629, 5, 328, 130, 3, 17183, 147, 3, 9, 1059, 13, 460, 203, 11, 1363, 2336, 348, 530, 128, 13, 8, 200, 19334, 44, 8, 97, 12, 161, 21, 376, 3, 18, 360, 119, 151, 133, 43, 141, 8, 5987, 11, 14241, 12, 103, 24, 5, 1]])\n",
    "\n",
    "data = {\n",
    "    \"input_data\": {\n",
    "        \"inputs\": inputs.tolist()\n",
    "    },\n",
    "    \"params\": {\n",
    "        \"max_length\": 150,\n",
    "        \"min_length\": 5,\n",
    "        \"length_penalty\": 2.0,\n",
    "        \"num_beams\": 4,\n",
    "        \"early_stopping\": True\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[]'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data =  {\n",
    "  \"input_data\": {},\n",
    "  \"params\": {}\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'https://customhf.westeurope.inference.ml.azure.com/score'\n",
    "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "api_key = '8opaGj8QBSgCYTukYKylGcuGxYeYRzJx'\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'herooooooooo-t5-small-finetun-1' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: b'[]'\n"
     ]
    }
   ],
   "source": [
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "    result = response.read()\n",
    "    print(\"Response:\", result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code:\", error.code)\n",
    "    print(\"Headers:\", error.info())\n",
    "    print(\"Error Response:\", error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request failed with status code: 424\n",
      "Headers: server: azureml-frontdoor\n",
      "date: Mon, 19 Feb 2024 10:05:53 GMT\n",
      "content-type: application/json\n",
      "content-length: 92\n",
      "x-ms-run-function-failed: True\n",
      "x-ms-server-version: azmlinfsrv/1.0.0\n",
      "x-ms-request-id: 5f13c4bf-48b0-4a3f-b346-98f18145ceeb\n",
      "x-request-id: 5f13c4bf-48b0-4a3f-b346-98f18145ceeb\n",
      "ms-azureml-model-error-reason: model_error\n",
      "ms-azureml-model-error-statuscode: 500\n",
      "azureml-model-deployment: herooooooooo-t5-small-finetun-1\n",
      "connection: close\n",
      "\n",
      "\n",
      "Error Response: {\"message\": \"An unexpected error occurred in scoring script. Check the logs for more info.\"}\n"
     ]
    }
   ],
   "source": [
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "    result = response.read()\n",
    "    print(\"Response:\", result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code:\", error.code)\n",
    "    print(\"Headers:\", error.info())\n",
    "    print(\"Error Response:\", error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request failed with status code: 424\n",
      "Headers: server: azureml-frontdoor\n",
      "date: Mon, 19 Feb 2024 10:06:43 GMT\n",
      "content-type: application/json\n",
      "content-length: 92\n",
      "x-ms-run-function-failed: True\n",
      "x-ms-server-version: azmlinfsrv/1.0.0\n",
      "x-ms-request-id: ed4eb667-1baa-4076-8280-e3cbbb035d52\n",
      "x-request-id: ed4eb667-1baa-4076-8280-e3cbbb035d52\n",
      "ms-azureml-model-error-reason: model_error\n",
      "ms-azureml-model-error-statuscode: 500\n",
      "azureml-model-deployment: herooooooooo-t5-small-finetun-1\n",
      "connection: close\n",
      "\n",
      "\n",
      "Error Response: {\"message\": \"An unexpected error occurred in scoring script. Check the logs for more info.\"}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "# Your updated data dictionary\n",
    "data = {\n",
    "    \"input_data\": {\n",
    "        \"inputs\": inputs.tolist()  # Assuming 'inputs' is already defined and formatted correctly\n",
    "    },\n",
    "    \"params\": {\n",
    "        \"max_length\": 150,\n",
    "        \"min_length\": 5,\n",
    "        \"length_penalty\": 2.0,\n",
    "        \"num_beams\": 4,\n",
    "        \"early_stopping\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Correctly encode your data dictionary to JSON and then to bytes\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "# Your endpoint URL\n",
    "url = 'https://customhf.westeurope.inference.ml.azure.com/score'\n",
    "# Headers including the API key and content type\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': ('Bearer ' + api_key),  # Ensure your API key is defined\n",
    "    'azureml-model-deployment': 'herooooooooo-t5-small-finetun-1'  # Specific deployment name if necessary\n",
    "}\n",
    "\n",
    "# Initialize the request with the URL, encoded body, and headers\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "# Try to open the URL and read the response\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "    result = response.read()\n",
    "    print(\"Response:\", result.decode('utf-8'))  # Decode the bytes response to string for printing\n",
    "except urllib.error.HTTPError as error:\n",
    "    # Handle HTTP errors\n",
    "    print(\"The request failed with status code:\", error.code)\n",
    "    print(\"Headers:\", error.info())\n",
    "    print(\"Error Response:\", error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
